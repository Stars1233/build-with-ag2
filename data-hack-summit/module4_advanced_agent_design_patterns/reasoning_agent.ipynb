{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1336fa2",
   "metadata": {},
   "source": [
    "# Reasoning Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f3465f",
   "metadata": {},
   "source": [
    "ReasoningAgent is designed to enhance language models' reasoning capabilities through systematic exploration of thought processes. By implementing the Tree of Thoughts (ToT) framework, it enables LLMs like GPT-4 and Llama to break down complex problems into manageable steps and explore multiple solution paths simultaneously.\n",
    "\n",
    "Here, we demonstrate the key features and capabilities of the ReasoningAgent, showing how it can effectively reason about problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f58541",
   "metadata": {},
   "source": [
    "Here, we demonstrate the key features and capabilities of the [`ReasoningAgent`](/docs/api-reference/autogen/agents/experimental/ReasoningAgent), showing how it can effectively reason about problems.\n",
    "\n",
    "## Search Strategies\n",
    "\n",
    "The [`ReasoningAgent`](/docs/api-reference/autogen/agents/experimental/ReasoningAgent) supports multiple search strategies for exploring the reasoning space:\n",
    "\n",
    "### 1. Beam Search (Default)\n",
    "- Maintains the top `k` most promising paths at each step\n",
    "- Efficient for problems with clear evaluation criteria\n",
    "- Configurable beam width to balance exploration vs computation\n",
    "- Special case: DFS mode (beam size = 1) for linear reasoning similar to Chain-of-Thought\n",
    "\n",
    "### 2. Monte Carlo Tree Search (MCTS)\n",
    "- Balances exploration and exploitation using UCT formula\n",
    "- Particularly effective for problems with delayed rewards\n",
    "- Stochastic exploration helps avoid local optima\n",
    "- Configurable number of simulations and exploration constant\n",
    "\n",
    "### 3. Language Agent Tree Search (LATS)\n",
    "- Provides immediate reflection feedback before the next simulation\n",
    "- Helps identify poor reasoning paths early for future improvement\n",
    "- Especially useful for complex multi-step reasoning\n",
    "\n",
    "## Core Components\n",
    "\n",
    "1. **Thinker Agent**: Generates potential next steps in the reasoning process\n",
    "2. **Grader Agent**: Evaluates the quality of each reasoning step\n",
    "3. **Interim Execution**: Option to execute the selected steps, enabling stepwise reasoning.\n",
    "4. **Code Execution**: a child user agent will execute code automatically during reasoning\n",
    "5. **Tree Structure**: Organizes thoughts hierarchically for systematic exploration\n",
    "6. **Visualization Tools**: Built-in Graphviz support for analyzing reasoning paths\n",
    "7. **Logging Features**: Log and save thinking trajectories to finetune the language model\n",
    "8. **Configuration Options**: The agent is highly configurable through a single `reason_config` dictionary\n",
    "9. **Customizabilty with scope**: Define task-specific context to guide the agentâ€™s reasoning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b9c1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from autogen.agents.experimental import ReasoningAgent, ThinkNode\n",
    "from autogen import UserProxyAgent, LLMConfig\n",
    "\n",
    "# Put your key in the OPENAI_API_KEY environment variable\n",
    "llm_config = LLMConfig(api_type=\"openai\", model=\"gpt-4o-mini\")\n",
    "\n",
    "verbose = True\n",
    "\n",
    "question = \"What is the expected maximum dice value if you can roll a 6-sided dice three times?\"\n",
    "random.seed(1)  # setup seed for reproducibility\n",
    "\n",
    "\n",
    "def last_meaningful_msg(sender, recipient, summary_args):\n",
    "    import warnings\n",
    "\n",
    "    if sender == recipient:\n",
    "        return \"TERMINATE\"\n",
    "\n",
    "    summary = \"\"\n",
    "    chat_messages = recipient.chat_messages[sender]\n",
    "\n",
    "    for msg in reversed(chat_messages):\n",
    "        try:\n",
    "            content = msg[\"content\"]\n",
    "            if isinstance(content, str):\n",
    "                summary = content.replace(\"TERMINATE\", \"\")\n",
    "            elif isinstance(content, list):\n",
    "                # Remove the `TERMINATE` word in the content list.\n",
    "                summary = \"\\n\".join(\n",
    "                    x[\"text\"].replace(\"TERMINATE\", \"\")\n",
    "                    for x in content\n",
    "                    if isinstance(x, dict) and \"text\" in x\n",
    "                )\n",
    "            if summary.strip().rstrip():\n",
    "                return summary\n",
    "        except (IndexError, AttributeError) as e:\n",
    "            warnings.warn(\n",
    "                f\"Cannot extract summary using last_msg: {e}. Using an empty str as summary.\",\n",
    "                UserWarning,\n",
    "            )\n",
    "    return summary\n",
    "\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    "    is_termination_msg=lambda x: True,  # terminate when reasoning agent responds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3123ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with llm_config:\n",
    "    reason_agent = ReasoningAgent(\n",
    "        name=\"reason_agent\",\n",
    "        system_message=\"answer math questions\",\n",
    "        reason_config={\"method\": \"dfs\", \"max_depth\": 3},  # Using DFS\n",
    "        silent=False,\n",
    "        # NOTE: it is equivalent to use beam size 1 for O1-style reasoning\n",
    "        # reason_config={\"method\": \"beam_search\", \"beam_size\": 1, \"max_depth\": 3},\n",
    "    )\n",
    "\n",
    "ans = user_proxy.initiate_chat(\n",
    "    reason_agent, message=question, summary_method=last_meaningful_msg\n",
    ")\n",
    "\n",
    "print(ans.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43a9604",
   "metadata": {},
   "source": [
    "## Save data to future training\n",
    "In this section, we will focus on saving the reasoning agent's decision-making data to help future training.\n",
    "\n",
    "By capturing the structure and content of the reasoning tree, we can create a valuable dataset that can be used to enhance the agent's learning process. This data will allow us to analyze the agent's reasoning patterns, improve its performance, and refine its ability to generate high-quality responses.\n",
    "\n",
    "The saved data can be utilized for various training methodologies, including supervised fine-tuning and reinforcement learning, ultimately contributing to the development of a more robust and effective reasoning agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = reason_agent._root.to_dict()\n",
    "with open(\"reasoning_tree.json\", \"w\") as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "# recover the node\n",
    "new_node = ThinkNode.from_dict(json.load(open(\"reasoning_tree.json\")))  # noqa: SIM115\n",
    "\n",
    "sft_data = reason_agent.extract_sft_dataset()\n",
    "rlhf_data = reason_agent.extract_rlhf_preference_dataset()\n",
    "\n",
    "print(rlhf_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
